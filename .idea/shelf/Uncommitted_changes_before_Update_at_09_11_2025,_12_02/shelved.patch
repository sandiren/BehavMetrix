Index: migrations/versions/0a30a34ea46c_initial_tables.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\"\"\"Initial tables\"\"\"\n\nfrom __future__ import annotations\n\nrevision = \"0a30a34ea46c\"\ndown_revision = None\nbranch_labels = None\ndepends_on = None\n\n\ndef upgrade() -> None:\n    from app import create_app, db\n\n    app = create_app()\n    with app.app_context():\n        db.create_all()\n\n\ndef downgrade() -> None:\n    from app import create_app, db\n\n    app = create_app()\n    with app.app_context():\n        db.drop_all()\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/migrations/versions/0a30a34ea46c_initial_tables.py b/migrations/versions/0a30a34ea46c_initial_tables.py
--- a/migrations/versions/0a30a34ea46c_initial_tables.py	(revision 6a9eed9c605be5eb9aa5e6393915b5b218f0a04d)
+++ b/migrations/versions/0a30a34ea46c_initial_tables.py	(date 1762675104175)
@@ -1,24 +1,176 @@
-"""Initial tables"""
+"""Initial tables
+
+Revision ID: 0a30a34ea46c
+Revises: 
+Create Date: 2025-11-09 07:32:54.777173
 
-from __future__ import annotations
+"""
+from alembic import op
+import sqlalchemy as sa
 
-revision = "0a30a34ea46c"
+
+# revision identifiers, used by Alembic.
+revision = '0a30a34ea46c'
 down_revision = None
 branch_labels = None
 depends_on = None
 
 
-def upgrade() -> None:
-    from app import create_app, db
+def upgrade():
+    # ### commands auto generated by Alembic - please adjust! ###
+    op.create_table('behavior_definitions',
+    sa.Column('id', sa.Integer(), nullable=False),
+    sa.Column('code', sa.String(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('description', sa.String(), nullable=True),
+    sa.Column('ontology_reference', sa.String(), nullable=True),
+    sa.PrimaryKeyConstraint('id'),
+    sa.UniqueConstraint('code')
+    )
+    op.create_table('data_ingestion_sessions',
+    sa.Column('id', sa.Integer(), nullable=False),
+    sa.Column('created_at', sa.DateTime(), nullable=False),
+    sa.Column('created_by', sa.String(), nullable=False),
+    sa.Column('source', sa.String(), nullable=False),
+    sa.Column('notes', sa.String(), nullable=True),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('enrichment_items',
+    sa.Column('id', sa.Integer(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('description', sa.String(), nullable=True),
+    sa.Column('category', sa.String(), nullable=True),
+    sa.Column('success_indicator', sa.String(), nullable=True),
+    sa.PrimaryKeyConstraint('id'),
+    sa.UniqueConstraint('name')
+    )
+    op.create_table('observers',
+    sa.Column('id', sa.Integer(), nullable=False),
+    sa.Column('name', sa.String(), nullable=False),
+    sa.Column('affiliation', sa.String(), nullable=True),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('animals',
+    sa.Column('id', sa.Integer(), nullable=False),
+    sa.Column('persistent_id', sa.String(), nullable=False),
+    sa.Column('name', sa.String(), nullable=True),
+    sa.Column('cage_id', sa.String(), nullable=False),
+    sa.Column('sex', sa.String(), nullable=False),
+    sa.Column('age', sa.Integer(), nullable=True),
+    sa.Column('weight_kg', sa.Float(), nullable=True),
+    sa.Column('species', sa.String(), nullable=False),
+    sa.Column('matriline', sa.String(), nullable=True),
+    sa.Column('date_of_birth', sa.DateTime(), nullable=True),
+    sa.Column('photo_url', sa.String(), nullable=True),
+    sa.Column('ingestion_session_id', sa.Integer(), nullable=True),
+    sa.ForeignKeyConstraint(['ingestion_session_id'], ['data_ingestion_sessions.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    with op.batch_alter_table('animals', schema=None) as batch_op:
+        batch_op.create_index(batch_op.f('ix_animals_cage_id'), ['cage_id'], unique=False)
+        batch_op.create_index(batch_op.f('ix_animals_persistent_id'), ['persistent_id'], unique=True)
+
+    op.create_table('behavior_logs',
+    sa.Column('id', sa.Integer(), nullable=False),
+    sa.Column('timestamp', sa.DateTime(), nullable=False),
+    sa.Column('context', sa.String(), nullable=True),
+    sa.Column('sample_type', sa.String(), nullable=False),
+    sa.Column('animal_id', sa.Integer(), nullable=False),
+    sa.Column('behavior_id', sa.Integer(), nullable=False),
+    sa.Column('observer_id', sa.Integer(), nullable=True),
+    sa.Column('interaction_partner_id', sa.Integer(), nullable=True),
+    sa.ForeignKeyConstraint(['animal_id'], ['animals.id'], ),
+    sa.ForeignKeyConstraint(['behavior_id'], ['behavior_definitions.id'], ),
+    sa.ForeignKeyConstraint(['interaction_partner_id'], ['animals.id'], ),
+    sa.ForeignKeyConstraint(['observer_id'], ['observers.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    with op.batch_alter_table('behavior_logs', schema=None) as batch_op:
+        batch_op.create_index(batch_op.f('ix_behavior_logs_timestamp'), ['timestamp'], unique=False)
+
+    op.create_table('enrichment_logs',
+    sa.Column('id', sa.Integer(), nullable=False),
+    sa.Column('timestamp', sa.DateTime(), nullable=False),
+    sa.Column('duration_minutes', sa.Float(), nullable=True),
+    sa.Column('response', sa.String(), nullable=True),
+    sa.Column('notes', sa.String(), nullable=True),
+    sa.Column('tag', sa.String(), nullable=True),
+    sa.Column('animal_id', sa.Integer(), nullable=False),
+    sa.Column('enrichment_item_id', sa.Integer(), nullable=False),
+    sa.ForeignKeyConstraint(['animal_id'], ['animals.id'], ),
+    sa.ForeignKeyConstraint(['enrichment_item_id'], ['enrichment_items.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('hormone_measurements',
+    sa.Column('id', sa.Integer(), nullable=False),
+    sa.Column('collected_at', sa.DateTime(), nullable=False),
+    sa.Column('hormone', sa.String(), nullable=False),
+    sa.Column('value', sa.Float(), nullable=False),
+    sa.Column('unit', sa.String(), nullable=False),
+    sa.Column('animal_id', sa.Integer(), nullable=False),
+    sa.ForeignKeyConstraint(['animal_id'], ['animals.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('incident_observations',
+    sa.Column('id', sa.Integer(), nullable=False),
+    sa.Column('created_at', sa.DateTime(), nullable=False),
+    sa.Column('reason', sa.String(), nullable=False),
+    sa.Column('description', sa.String(), nullable=True),
+    sa.Column('attachment_url', sa.String(), nullable=True),
+    sa.Column('tags', sa.String(), nullable=True),
+    sa.Column('animal_id', sa.Integer(), nullable=True),
+    sa.ForeignKeyConstraint(['animal_id'], ['animals.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('rank_scores',
+    sa.Column('id', sa.Integer(), nullable=False),
+    sa.Column('created_at', sa.DateTime(), nullable=False),
+    sa.Column('elo_score', sa.Float(), nullable=False),
+    sa.Column('davids_score', sa.Float(), nullable=True),
+    sa.Column('instability_flag', sa.Boolean(), nullable=False),
+    sa.Column('animal_id', sa.Integer(), nullable=False),
+    sa.ForeignKeyConstraint(['animal_id'], ['animals.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    op.create_table('stress_logs',
+    sa.Column('id', sa.Integer(), nullable=False),
+    sa.Column('date', sa.DateTime(), nullable=False),
+    sa.Column('stress_score', sa.Integer(), nullable=False),
+    sa.Column('withdrawal', sa.Boolean(), nullable=False),
+    sa.Column('fear_grimace', sa.Boolean(), nullable=False),
+    sa.Column('self_biting', sa.Boolean(), nullable=False),
+    sa.Column('notes', sa.String(), nullable=True),
+    sa.Column('animal_id', sa.Integer(), nullable=False),
+    sa.ForeignKeyConstraint(['animal_id'], ['animals.id'], ),
+    sa.PrimaryKeyConstraint('id')
+    )
+    with op.batch_alter_table('stress_logs', schema=None) as batch_op:
+        batch_op.create_index(batch_op.f('ix_stress_logs_date'), ['date'], unique=False)
+
+    # ### end Alembic commands ###
 
-    app = create_app()
-    with app.app_context():
-        db.create_all()
 
+def downgrade():
+    # ### commands auto generated by Alembic - please adjust! ###
+    with op.batch_alter_table('stress_logs', schema=None) as batch_op:
+        batch_op.drop_index(batch_op.f('ix_stress_logs_date'))
 
-def downgrade() -> None:
-    from app import create_app, db
+    op.drop_table('stress_logs')
+    op.drop_table('rank_scores')
+    op.drop_table('incident_observations')
+    op.drop_table('hormone_measurements')
+    op.drop_table('enrichment_logs')
+    with op.batch_alter_table('behavior_logs', schema=None) as batch_op:
+        batch_op.drop_index(batch_op.f('ix_behavior_logs_timestamp'))
 
-    app = create_app()
-    with app.app_context():
-        db.drop_all()
+    op.drop_table('behavior_logs')
+    with op.batch_alter_table('animals', schema=None) as batch_op:
+        batch_op.drop_index(batch_op.f('ix_animals_persistent_id'))
+        batch_op.drop_index(batch_op.f('ix_animals_cage_id'))
+
+    op.drop_table('animals')
+    op.drop_table('observers')
+    op.drop_table('enrichment_items')
+    op.drop_table('data_ingestion_sessions')
+    op.drop_table('behavior_definitions')
+    # ### end Alembic commands ###
Index: migrations/env.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from __future__ import annotations\n\nimport logging\nfrom logging.config import fileConfig\n\nfrom alembic import context\nfrom sqlalchemy import engine_from_config, pool\n\nfrom app import create_app, db\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\nlogger = logging.getLogger(\"alembic.env\")\n\napp = create_app()\n\nwith app.app_context():\n    target_metadata = db.metadata\n\n\ndef run_migrations_offline() -> None:\n    \"\"\"Run migrations in 'offline' mode.\"\"\"\n\n    url = app.config.get(\"SQLALCHEMY_DATABASE_URI\")\n    context.configure(\n        url=url,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        compare_type=True,\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef run_migrations_online() -> None:\n    \"\"\"Run migrations in 'online' mode.\"\"\"\n\n    configuration = config.get_section(config.config_ini_section) or {}\n    configuration[\"sqlalchemy.url\"] = app.config.get(\"SQLALCHEMY_DATABASE_URI\")\n\n    connectable = engine_from_config(\n        configuration,\n        prefix=\"sqlalchemy.\",\n        poolclass=pool.NullPool,\n    )\n\n    with connectable.connect() as connection:\n        context.configure(\n            connection=connection,\n            target_metadata=target_metadata,\n            compare_type=True,\n        )\n\n        with context.begin_transaction():\n            context.run_migrations()\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/migrations/env.py b/migrations/env.py
--- a/migrations/env.py	(revision 6a9eed9c605be5eb9aa5e6393915b5b218f0a04d)
+++ b/migrations/env.py	(date 1762675104192)
@@ -1,59 +1,106 @@
-from __future__ import annotations
-
 import logging
 from logging.config import fileConfig
 
+from flask import current_app
+
 from alembic import context
-from sqlalchemy import engine_from_config, pool
-
-from app import create_app, db
 
 # this is the Alembic Config object, which provides
 # access to the values within the .ini file in use.
 config = context.config
 
-if config.config_file_name is not None:
-    fileConfig(config.config_file_name)
-logger = logging.getLogger("alembic.env")
+# Interpret the config file for Python logging.
+# This line sets up loggers basically.
+fileConfig(config.config_file_name)
+logger = logging.getLogger('alembic.env')
+
 
-app = create_app()
+def get_engine():
+    try:
+        # this works with Flask-SQLAlchemy<3 and Alchemical
+        return current_app.extensions['migrate'].db.get_engine()
+    except (TypeError, AttributeError):
+        # this works with Flask-SQLAlchemy>=3
+        return current_app.extensions['migrate'].db.engine
 
-with app.app_context():
-    target_metadata = db.metadata
 
+def get_engine_url():
+    try:
+        return get_engine().url.render_as_string(hide_password=False).replace(
+            '%', '%%')
+    except AttributeError:
+        return str(get_engine().url).replace('%', '%%')
 
-def run_migrations_offline() -> None:
-    """Run migrations in 'offline' mode."""
 
-    url = app.config.get("SQLALCHEMY_DATABASE_URI")
+# add your model's MetaData object here
+# for 'autogenerate' support
+# from myapp import mymodel
+# target_metadata = mymodel.Base.metadata
+config.set_main_option('sqlalchemy.url', get_engine_url())
+target_db = current_app.extensions['migrate'].db
+
+# other values from the config, defined by the needs of env.py,
+# can be acquired:
+# my_important_option = config.get_main_option("my_important_option")
+# ... etc.
+
+
+def get_metadata():
+    if hasattr(target_db, 'metadatas'):
+        return target_db.metadatas[None]
+    return target_db.metadata
+
+
+def run_migrations_offline():
+    """Run migrations in 'offline' mode.
+
+    This configures the context with just a URL
+    and not an Engine, though an Engine is acceptable
+    here as well.  By skipping the Engine creation
+    we don't even need a DBAPI to be available.
+
+    Calls to context.execute() here emit the given string to the
+    script output.
+
+    """
+    url = config.get_main_option("sqlalchemy.url")
     context.configure(
-        url=url,
-        target_metadata=target_metadata,
-        literal_binds=True,
-        compare_type=True,
+        url=url, target_metadata=get_metadata(), literal_binds=True
     )
 
     with context.begin_transaction():
         context.run_migrations()
 
 
-def run_migrations_online() -> None:
-    """Run migrations in 'online' mode."""
+def run_migrations_online():
+    """Run migrations in 'online' mode.
+
+    In this scenario we need to create an Engine
+    and associate a connection with the context.
 
-    configuration = config.get_section(config.config_ini_section) or {}
-    configuration["sqlalchemy.url"] = app.config.get("SQLALCHEMY_DATABASE_URI")
+    """
 
-    connectable = engine_from_config(
-        configuration,
-        prefix="sqlalchemy.",
-        poolclass=pool.NullPool,
-    )
+    # this callback is used to prevent an auto-migration from being generated
+    # when there are no changes to the schema
+    # reference: http://alembic.zzzcomputing.com/en/latest/cookbook.html
+    def process_revision_directives(context, revision, directives):
+        if getattr(config.cmd_opts, 'autogenerate', False):
+            script = directives[0]
+            if script.upgrade_ops.is_empty():
+                directives[:] = []
+                logger.info('No changes in schema detected.')
+
+    conf_args = current_app.extensions['migrate'].configure_args
+    if conf_args.get("process_revision_directives") is None:
+        conf_args["process_revision_directives"] = process_revision_directives
+
+    connectable = get_engine()
 
     with connectable.connect() as connection:
         context.configure(
             connection=connection,
-            target_metadata=target_metadata,
-            compare_type=True,
+            target_metadata=get_metadata(),
+            **conf_args
         )
 
         with context.begin_transaction():
